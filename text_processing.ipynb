{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a362772-8072-40f0-8b33-78cf01e7ca36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5cdb54-a76e-4e01-af70-3a78ebcc36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.chdir('/home/prabhur/reddit_project/data')\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#for text processing\n",
    "import regex as re\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cc22db-7315-49e2-9168-8984a8aa6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_df(city):\n",
    "    cons_df = pd.DataFrame()\n",
    "    for file in os.listdir():\n",
    "        if city in file:\n",
    "            _ = pd.read_pickle(file)\n",
    "            cons_df = pd.concat([cons_df, _.text])\n",
    "            cons_df.reset_index(drop = True, inplace = True)\n",
    "    cons_df.columns = [\"text\"]\n",
    "    cons_df = cons_df[cons_df[\"text\"] != \"[deleted]\"] #deleted posts\n",
    "    return cons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f230da-5677-43d8-85f7-cb3d166db282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(x):\n",
    "    \"\"\"returns the tokenized and lemmatized words from the text provided\"\"\"\n",
    "\n",
    "    #using regex to remove\n",
    "    x = re.sub(r\"!\\[gif\\]\\(emote\\|free_emotes_pack\\|\\w+\\)|!\\[gif\\]\\(giphy\\|\\w+\\)\", \"\", x)  #with gifs or emoticons\n",
    "    x = re.sub(r\"http.+\\b\", \"\", x) #hyperlinks\n",
    "    x = re.sub(r\"[^A-Za-z\\ +]\", \"\", x) #non-alphabetic character based words\n",
    "\n",
    "    #tokenization and lemmatization\n",
    "    doc = nlp(x)\n",
    "    return [str(word.lemma_).lower().strip() for word in doc if str(word).lower() not in STOP_WORDS and len(str(word).strip())>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec75175e-9f8a-46fd-aec5-4f946dfaae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49940, 1)\n",
      "Text processing takes ~5.21 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>Chutiyap advice ghani</td>\n",
       "      <td>[chutiyap, advice, ghani]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>Congratulations bro but yaha Laxmi nagar se b ...</td>\n",
       "      <td>[congratulation, bro, yaha, laxmi, nagar, se, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11443</th>\n",
       "      <td>Dosto gaandhi ji ki ashtiya beh gyi iss pani m...</td>\n",
       "      <td>[dosto, gaandhi, ji, ki, ashtiya, beh, gyi, is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "6934                               Chutiyap advice ghani   \n",
       "11193  Congratulations bro but yaha Laxmi nagar se b ...   \n",
       "11443  Dosto gaandhi ji ki ashtiya beh gyi iss pani m...   \n",
       "\n",
       "                                          processed_text  \n",
       "6934                           [chutiyap, advice, ghani]  \n",
       "11193  [congratulation, bro, yaha, laxmi, nagar, se, ...  \n",
       "11443  [dosto, gaandhi, ji, ki, ashtiya, beh, gyi, is...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_df = create_base_df('del')\n",
    "print(del_df.shape)\n",
    "start = time.time() \n",
    "del_df[\"processed_text\"] = del_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "del_df.to_pickle(\"del_df.pkl\")\n",
    "del_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36e138b4-493e-45de-9e20-ffc80a6347eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48551, 1)\n",
      "Text processing takes ~5.5 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>Where are these recipes?</td>\n",
       "      <td>[recipe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24436</th>\n",
       "      <td>Can relate, have read the fountainhead by Ayn ...</td>\n",
       "      <td>[relate, read, fountainhead, ayn, rand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18160</th>\n",
       "      <td>Colaba is usually clean. You'll find people ap...</td>\n",
       "      <td>[colaba, usually, clean, ll, find, people, apl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "5825                            Where are these recipes?   \n",
       "24436  Can relate, have read the fountainhead by Ayn ...   \n",
       "18160  Colaba is usually clean. You'll find people ap...   \n",
       "\n",
       "                                          processed_text  \n",
       "5825                                            [recipe]  \n",
       "24436            [relate, read, fountainhead, ayn, rand]  \n",
       "18160  [colaba, usually, clean, ll, find, people, apl...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mum_df = create_base_df('mum')\n",
    "print(mum_df.shape)\n",
    "start = time.time() \n",
    "mum_df[\"processed_text\"] = mum_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "mum_df.to_pickle(\"mum_df.pkl\")\n",
    "mum_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c811088-6fa4-430c-b9f1-2b1da8e0064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47843, 1)\n",
      "Text processing takes ~6.34 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13804</th>\n",
       "      <td>Bro metro is seriously one of the recent best ...</td>\n",
       "      <td>[bro, metro, seriously, recent, good, investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46507</th>\n",
       "      <td>Builder's in Bangalore are using 50% of water ...</td>\n",
       "      <td>[builder, bangalore, water, guess, new, project]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>Apply Kirchhoff's law.</td>\n",
       "      <td>[apply, kirchhoffs, law]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "13804  Bro metro is seriously one of the recent best ...   \n",
       "46507  Builder's in Bangalore are using 50% of water ...   \n",
       "4511                              Apply Kirchhoff's law.   \n",
       "\n",
       "                                          processed_text  \n",
       "13804  [bro, metro, seriously, recent, good, investme...  \n",
       "46507   [builder, bangalore, water, guess, new, project]  \n",
       "4511                            [apply, kirchhoffs, law]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ban_df = create_base_df('ban')\n",
    "print(ban_df.shape)\n",
    "start = time.time() \n",
    "ban_df[\"processed_text\"] = ban_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "ban_df.to_pickle(\"ban_df.pkl\")\n",
    "ban_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f53dfe-8524-4a8b-b574-73ac9c97e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51350, 1)\n",
      "Text processing takes ~6.38 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>I'm doing OK on masks but I wanted to say you ...</td>\n",
       "      <td>[ok, mask, want, awesome, holy, heck, honestly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>After overwhelmingly negative reaction from th...</td>\n",
       "      <td>[overwhelmingly, negative, reaction, public, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36805</th>\n",
       "      <td>Preditors usually prey close to home, he may l...</td>\n",
       "      <td>[preditor, usually, prey, close, home, live, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "13300  I'm doing OK on masks but I wanted to say you ...   \n",
       "31400  After overwhelmingly negative reaction from th...   \n",
       "36805  Preditors usually prey close to home, he may l...   \n",
       "\n",
       "                                          processed_text  \n",
       "13300  [ok, mask, want, awesome, holy, heck, honestly...  \n",
       "31400  [overwhelmingly, negative, reaction, public, m...  \n",
       "36805  [preditor, usually, prey, close, home, live, c...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df = create_base_df('bos')\n",
    "print(bos_df.shape)\n",
    "start = time.time() \n",
    "bos_df[\"processed_text\"] = bos_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "bos_df.to_pickle(\"bos_df.pkl\")\n",
    "bos_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91c1da7f-2b04-4791-b263-a8d67a2cbe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51503, 1)\n",
      "Text processing takes ~6.15 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>I wish I knew Karl Pilkington was in town</td>\n",
       "      <td>[wish, know, karl, pilkington, town]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37816</th>\n",
       "      <td>Well, let’s not be too snide. There have been ...</td>\n",
       "      <td>[lets, snide, roam, band, hundred, teen, riot,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17795</th>\n",
       "      <td>Reported for sexual content</td>\n",
       "      <td>[report, sexual, content]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "10197          I wish I knew Karl Pilkington was in town   \n",
       "37816  Well, let’s not be too snide. There have been ...   \n",
       "17795                        Reported for sexual content   \n",
       "\n",
       "                                          processed_text  \n",
       "10197               [wish, know, karl, pilkington, town]  \n",
       "37816  [lets, snide, roam, band, hundred, teen, riot,...  \n",
       "17795                          [report, sexual, content]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_df = create_base_df('chi')\n",
    "print(chi_df.shape)\n",
    "start = time.time() \n",
    "chi_df[\"processed_text\"] = chi_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "chi_df.to_pickle(\"chi_df.pkl\")\n",
    "chi_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d27eb41-29d8-4ee3-8f3e-48b8179b80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56433, 1)\n",
      "Text processing takes ~6.84 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42273</th>\n",
       "      <td>:: nervously raises hand :: I live in a hewse</td>\n",
       "      <td>[nervously, raise, hand, live, hewse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47984</th>\n",
       "      <td>Karate</td>\n",
       "      <td>[karate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>I don't know if it was my luck about a decade ...</td>\n",
       "      <td>[not, know, luck, decade, ago, certain, coin, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "42273      :: nervously raises hand :: I live in a hewse   \n",
       "47984                                             Karate   \n",
       "44984  I don't know if it was my luck about a decade ...   \n",
       "\n",
       "                                          processed_text  \n",
       "42273              [nervously, raise, hand, live, hewse]  \n",
       "47984                                           [karate]  \n",
       "44984  [not, know, luck, decade, ago, certain, coin, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df = create_base_df('nyc')\n",
    "print(nyc_df.shape)\n",
    "start = time.time() \n",
    "nyc_df[\"processed_text\"] = nyc_df[\"text\"].apply(lambda x: text_processing(x))\n",
    "end = time.time()\n",
    "print(f\"Text processing takes ~{round((end-start)/60,2)} mins\")\n",
    "nyc_df.to_pickle(\"nyc_df.pkl\")\n",
    "nyc_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd15c9a-d478-4aa8-b88a-5aa29161746a",
   "metadata": {},
   "source": [
    "#### pending \n",
    "- topic modeling\n",
    "- visualization (from assignment)\n",
    "- pylab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5453ec-99db-41a3-8e11-90175ad5a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langdetect  #to check for english language\n",
    "# ##https://pypi.org/project/langdetect/\n",
    "\n",
    "# from langdetect import detect\n",
    "# test = del_df.iloc[:3,:]\n",
    "# # test\n",
    "# y = detect(test.loc[0,\"text\"])\n",
    "# y\n",
    "\n",
    "##tried language detect, both on the original text and also after tokenization and cleanup. But langdetect did not have good results\n",
    "##upon further research it seems like this may be because langdetect needs longer sentences to detect the language correctly.\n",
    "# test[\"lang\"] = test[\"text\"].apply(lambda x: detect(x)) \n",
    "# test\n",
    "# del_df[\"lang\"].nunique()\n",
    "# del_df)\n",
    "\n",
    "# from string import punctuation\n",
    "# # import nltk #too slow with tokenization\n",
    "# # test[\"text2\"] = test[\"text\"].apply(lambda x: \" \".join([word.strip().lower() for word in x.split(\" \") if word not in punctuation])) #langdetect alone did not have good results\n",
    "# test[\"lang2\"] = test[\"text2\"].apply(lambda x: detect(x)) #langdetect alone did not have good results\n",
    "# test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
